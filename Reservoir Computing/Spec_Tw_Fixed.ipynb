{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does Specializing More than Once Improve Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from res_specialization import *\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIALS      = 1000\n",
    "NUM_TO_SPEC = 3\n",
    "TOL = 5\n",
    "\n",
    "diff_eq_params = {\"x0\": [-20, 10, -.5], \n",
    "                  \"begin\": 0, \n",
    "                  \"end\": 60, \n",
    "                  \"timesteps\":60000}\n",
    "\n",
    "res_params = {\"res_sz\": 30, \n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .12, \n",
    "              \"ridge_alpha\": .00001, \n",
    "              \"spect_rad\": .9, \n",
    "              \"gamma\": 1., \n",
    "              \"sigma\": 0.12,\n",
    "              \"uniform_weights\": True\n",
    "             }\n",
    "\n",
    "results = dict()\n",
    "\n",
    "\n",
    "def save_results():\n",
    "    pickle.dump(results, open(\"spec_tw.pkl\",\"wb\"))\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, train_t, u = lorenz_equ(**diff_eq_params )\n",
    "train_t = t[30000:55000]\n",
    "test_t  = t[55000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-run grant figure trials to get prediction length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_err       = []\n",
    "random_pred      = []\n",
    "specialized_err  = []\n",
    "specialized_pred = []\n",
    "\n",
    "\n",
    "spec_sizes       = []\n",
    "spec_edges       = []\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    \n",
    "    ######################\n",
    "    # Random graph\n",
    "    ######################\n",
    "    \n",
    "    # Make rc\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Make predicitions\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    \n",
    "    # Store Error\n",
    "    random_err.append(err)\n",
    "    random_pred.append(how_long_accurate(u(test_t), test_pre, tol=TOL))\n",
    "    \n",
    "    #######################\n",
    "    # Specialize graph\n",
    "    ######################\n",
    "    \n",
    "    A = specialize_best_nodes(rc, NUM_TO_SPEC, u, train_t, r_0=r_0)\n",
    "    spec_sizes.append(A.shape[0])\n",
    "    spec_edges.append(np.sum(A != 0))\n",
    "    \n",
    "    rc = make_res_comp(A, res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    specialized_err.append(err)\n",
    "    specialized_pred.append(how_long_accurate(u(test_t), test_pre, tol=TOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prediction Length: 175.961\n",
      "Mean Prediction Length: 2463.711\n"
     ]
    }
   ],
   "source": [
    "results[\"random_err\"]       = random_err\n",
    "results[\"random_pred\"]      = random_pred\n",
    "results[\"specialized_err\"]  = specialized_err\n",
    "results[\"specialized_pred\"] = specialized_pred\n",
    "results[\"spec_sizes\"]       = spec_sizes\n",
    "results[\"spec_edges\"]       = spec_edges\n",
    "save_results()\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(random_pred)))\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(specialized_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control: Same sizes and same edge densities as previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_edge_err = []\n",
    "match_edge_pred = []\n",
    "\n",
    "for s,e in zip(spec_sizes,spec_edges):\n",
    "    # Test random graph with same number of edges as specialized graphs\n",
    "    \n",
    "    # Make and fit RC\n",
    "    res_params[\"res_sz\"] = s\n",
    "    res_params[\"connect_p\"] = e/(s**2)\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Predict\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    match_edge_err.append(err)\n",
    "    match_edge_pred.append(how_long_accurate(u(test_t), test_pre, tol=TOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prediction Length: 1395.971\n"
     ]
    }
   ],
   "source": [
    "results[\"match_edge_err\"] = match_edge_err\n",
    "results[\"match_edge_pred\"] = match_edge_pred\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(match_edge_pred)))\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialization without finding best nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_params = {\"res_sz\": 30, \n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .12, \n",
    "              \"ridge_alpha\": .00001, \n",
    "              \"spect_rad\": .9, \n",
    "              \"gamma\": 1., \n",
    "              \"sigma\": 0.12,\n",
    "              \"uniform_weights\": True\n",
    "             }\n",
    "\n",
    "random_specialized_err  = []\n",
    "random_specialized_pred = []\n",
    "rspec_sizes         = []\n",
    "rspec_edges         = []\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    # Random graph\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    \n",
    "    # Turn reservoir to integer adj matrix\n",
    "    A = rc.res\n",
    "    for j in range(A.shape[0]): A[j,j] = 0\n",
    "    A = (A != 0)*1\n",
    "    \n",
    "    # Specialize the reservoir\n",
    "    A = specializeGraph(A, random.sample(list(range(30)),27))\n",
    "    \n",
    "    # Store data\n",
    "    rspec_sizes.append(A.shape[0])\n",
    "    rspec_edges.append(np.sum(A != 0))\n",
    "    \n",
    "    # Make new reservoir\n",
    "    rc = make_res_comp(A, res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Get predicitons\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    \n",
    "    # Store data\n",
    "    random_specialized_err.append(err)\n",
    "    random_specialized_pred.append(how_long_accurate(u(test_t), test_pre, tol=TOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prediction Length: 2026.941\n"
     ]
    }
   ],
   "source": [
    "results[\"random_specialized_err\"]  = random_specialized_err\n",
    "results[\"random_specialized_pred\"] = random_specialized_pred\n",
    "results[\"rspec_sizes\"]             = rspec_sizes\n",
    "results[\"rspec_edges\"]             = rspec_edges\n",
    "\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(random_specialized_pred)))\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control: Same sizes and same edge densities as previous experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_match_edge_err  = []\n",
    "rand_match_edge_pred = []\n",
    "\n",
    "for s,e in zip(rspec_sizes, rspec_edges):\n",
    "    # Test random graph\n",
    "    \n",
    "    # Make and fit RC\n",
    "    res_params[\"res_sz\"] = s\n",
    "    res_params[\"connect_p\"] = e/(s**2)\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Predict\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    rand_match_edge_err.append(err)\n",
    "    rand_match_edge_pred.append(how_long_accurate(u(test_t), test_pre, tol=TOL))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Prediction Length: 1153.45\n"
     ]
    }
   ],
   "source": [
    "results[\"rand_match_edge_err\"]  = rand_match_edge_err\n",
    "results[\"rand_match_edge_pred\"] = rand_match_edge_pred\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(rand_match_edge_pred)))\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Specialize Twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_params = {\"res_sz\": 30, \n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .12, \n",
    "              \"ridge_alpha\": .00001, \n",
    "              \"spect_rad\": .9, \n",
    "              \"gamma\": 1., \n",
    "              \"sigma\": 0.12,\n",
    "              \"uniform_weights\": True\n",
    "             }\n",
    "\n",
    "spec_tw_pre = []\n",
    "spec_tw_err = []\n",
    "tw_edges = []\n",
    "tw_sizes = []\n",
    "HOW_MANY_SPEC = 2\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    # Make rc\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    rc.fit(train_t,u)\n",
    "    \n",
    "    # Specialize 2 times\n",
    "    for i in range(HOW_MANY_SPEC):\n",
    "        A = specialize_best_nodes(rc, NUM_TO_SPEC, u, train_t, r_0=r_0)\n",
    "        rc = make_res_comp(A, res_params)\n",
    "        r_0 = rc.state_0\n",
    "        err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Predict the system states\n",
    "    tw_sizes.append(A.shape[0])\n",
    "    tw_edges.append(np.sum(A != 0))\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    spec_tw_err.append(err)\n",
    "    spec_tw_pre.append(how_long_accurate(u(test_t), test_pre,tol=TOL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"spec_tw_pre\"] = spec_tw_pre\n",
    "results[\"spec_tw_err\"] = spec_tw_err\n",
    "results[\"tw_edges\"] = tw_edges\n",
    "results[\"tw_sizes\"] = tw_sizes\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Prediction Length: {}\".format(np.mean(spec_tw_pre)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control: Same sizes and same edge densities as previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_match_edge_err  = []\n",
    "tw_match_edge_pred = []\n",
    "\n",
    "for s,e in zip(tw_sizes, tw_edges):\n",
    "    # Test random graph\n",
    "    \n",
    "    # Make and fit RC\n",
    "    res_params[\"res_sz\"] = s\n",
    "    res_params[\"connect_p\"] = e/(s**2)\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Predict\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    tw_match_edge_err.append(err)\n",
    "    tw_match_edge_pred.append(how_long_accurate(u(test_t),test_pre,tol=TOL))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"tw_match_edge_err\"] = tw_match_edge_err\n",
    "results[\"tw_match_edge_pred\"] = tw_match_edge_pred\n",
    "save_results()\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(tw_match_edge_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Specialize Three Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_params = {\"res_sz\": 30, \n",
    "              \"activ_f\": np.tanh,\n",
    "              \"connect_p\": .12, \n",
    "              \"ridge_alpha\": .00001, \n",
    "              \"spect_rad\": .9, \n",
    "              \"gamma\": 1., \n",
    "              \"sigma\": 0.12,\n",
    "              \"uniform_weights\": True\n",
    "             }\n",
    "\n",
    "spec_thr_pre = []\n",
    "spec_thr_err = []\n",
    "thr_edges = []\n",
    "thr_sizes = []\n",
    "HOW_MANY_SPEC = 3\n",
    "\n",
    "for i in range(TRIALS):\n",
    "    # Make RC\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    rc.fit(train_t,u)\n",
    "    \n",
    "    # Specialize 3 times\n",
    "    for i in range(HOW_MANY_SPEC):\n",
    "        A = specialize_best_nodes(rc, NUM_TO_SPEC, u, train_t, r_0=r_0)\n",
    "        rc = make_res_comp(A, res_params)\n",
    "        r_0 = rc.state_0\n",
    "        err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Make predicitons\n",
    "    thr_sizes.append(A.shape[0])\n",
    "    thr_edges.append(np.sum(A != 0))\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    spec_thr_err.append(err)\n",
    "    spec_thr_pre.append(how_long_accurate(u(test_t), test_pre,tol=TOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"spec_thr_pre\"] = spec_thr_pre\n",
    "results[\"spec_thr_err\"] = spec_thr_err\n",
    "results[\"thr_edges\"] = thr_edges\n",
    "results[\"thr_sizes\"] = thr_sizes\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(spec_thr_pre)))\n",
    "\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control: Same sizes and same edge densities as previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_match_edge_err  = []\n",
    "thr_match_edge_pred = []\n",
    "\n",
    "for s,e in zip(thr_sizes, thr_edges):\n",
    "    # Test random graph\n",
    "    \n",
    "    # Make and fit RC\n",
    "    res_params[\"res_sz\"] = s\n",
    "    res_params[\"connect_p\"] = e/(s**2)\n",
    "    rc = ResComp(3,3,**res_params)\n",
    "    r_0 = rc.state_0\n",
    "    err = rc.fit(train_t,u)\n",
    "    \n",
    "    # Predict systems\n",
    "    test_pre = rc.predict(test_t)\n",
    "    train_pre = rc.predict(train_t, r_0=r_0)\n",
    "    thr_match_edge_err.append(err)\n",
    "    thr_match_edge_pred.append(how_long_accurate(u(test_t),test_pre,tol=TOL))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"thr_match_edge_err\"] = thr_match_edge_err\n",
    "results[\"thr_match_edge_pred\"] = thr_match_edge_pred\n",
    "print(\"Mean Prediction Length: {}\".format(np.mean(thr_match_edge_pred)))\n",
    "\n",
    "save_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize results into dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"random_specialized\",\"specialized\",\"spec_twice\", \"spec_three\"]\n",
    "df = pd.DataFrame(results)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"random_specialized_err\",\"specialized_err\",\"spec_tw_err\", \"spec_thr_err\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"rand_match_edge_err\", \"match_edge_err\", \"tw_match_edge_err\", \"thr_match_edge_err\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"random_specialized_pred\",\"specialized_pred\",\"spec_tw_pre\", \"spec_thr_pre\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"rand_match_edge_pred\", \"match_edge_pred\", \"tw_match_edge_pred\", \"thr_match_edge_pred\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = df[[\"rspec_sizes\", \"spec_sizes\", \"tw_sizes\", \"thr_sizes\"]]\n",
    "sizes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df[[\"rspec_edges\", \"spec_edges\", \"tw_edges\", \"thr_edges\"]]\n",
    "edges.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity: (num edges)/(num nodes)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"random_specialized\",\"specialized\",\"spec_twice\", \"spec_three\"]\n",
    "edge_prob = pd.DataFrame(np.array(edges)/(np.array(sizes)**2),columns=labels)\n",
    "edge_prob.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"random_err\", \"random_pred\"]].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
